{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapy 2.1.0 - project: assigment_2\n",
      "\n",
      "Usage:\n",
      "  scrapy <command> [options] [args]\n",
      "\n",
      "Available commands:\n",
      "  bench         Run quick benchmark test\n",
      "  check         Check spider contracts\n",
      "  crawl         Run a spider\n",
      "  edit          Edit spider\n",
      "  fetch         Fetch a URL using the Scrapy downloader\n",
      "  genspider     Generate new spider using pre-defined templates\n",
      "  list          List available spiders\n",
      "  parse         Parse URL (using its spider) and print the results\n",
      "  runspider     Run a self-contained spider (without creating a project)\n",
      "  settings      Get settings values\n",
      "  shell         Interactive scraping console\n",
      "  startproject  Create new project\n",
      "  version       Print Scrapy version\n",
      "  view          Open URL in browser, as seen by Scrapy\n",
      "\n",
      "Use \"scrapy <command> -h\" to see more info about a command\n"
     ]
    }
   ],
   "source": [
    "!scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-28 09:03:38 [scrapy.utils.log] INFO: Scrapy 2.1.0 started (bot: assigment_2)\n",
      "2020-06-28 09:03:38 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 13:42:34) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.4.0-x86_64-i386-64bit\n",
      "2020-06-28 09:03:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2020-06-28 09:03:38 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'assigment_2',\n",
      " 'DOWNLOAD_DELAY': 2,\n",
      " 'NEWSPIDER_MODULE': 'assigment_2.spiders',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_MODULES': ['assigment_2.spiders'],\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'}\n",
      "2020-06-28 09:03:38 [scrapy.extensions.telnet] INFO: Telnet Password: f6f8bbe2abec6d97\n",
      "2020-06-28 09:03:38 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2020-06-28 09:03:39 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2020-06-28 09:03:39 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2020-06-28 09:03:39 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2020-06-28 09:03:39 [scrapy.core.engine] INFO: Spider opened\n",
      "2020-06-28 09:03:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2020-06-28 09:03:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2020-06-28 09:03:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/robots.txt> (referer: None)\n",
      "2020-06-28 09:03:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films?showType=3> (referer: None)\n",
      "https://maoyan.com/films/1250952\n",
      "https://maoyan.com/films/1218273\n",
      "https://maoyan.com/films/344990\n",
      "https://maoyan.com/films/1211270\n",
      "2020-06-28 09:03:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1250952> (referer: https://maoyan.com/films?showType=3)\n",
      "https://maoyan.com/films/1218029\n",
      "https://maoyan.com/films/246061\n",
      "测试 天气之子\n",
      " 爱情 动画 奇幻\n",
      "2019-11-01中国大陆上映\n",
      "2020-06-28 09:03:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1250952>\n",
      "{'film_name': '天气之子', 'film_type': ' 爱情 动画 奇幻', 'plan_time': '2019-11-01中国大陆上映'}\n",
      "https://maoyan.com/films/1251639\n",
      "2020-06-28 09:03:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1218273> (referer: https://maoyan.com/films?showType=3)\n",
      "https://maoyan.com/films/344264\n",
      "https://maoyan.com/films/1227006\n",
      "测试 误杀\n",
      " 剧情 犯罪\n",
      "2019-12-13中国大陆上映\n",
      "2020-06-28 09:03:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1218273>\n",
      "{'film_name': '误杀', 'film_type': ' 剧情 犯罪', 'plan_time': '2019-12-13中国大陆上映'}\n",
      "https://maoyan.com/films/343355\n",
      "2020-06-28 09:03:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/344990> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 唐人街探案2\n",
      " 喜剧 动作 悬疑\n",
      "2018-02-16中国大陆上映\n",
      "2020-06-28 09:03:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/344990>\n",
      "{'film_name': '唐人街探案2',\n",
      " 'film_type': ' 喜剧 动作 悬疑',\n",
      " 'plan_time': '2018-02-16中国大陆上映'}\n",
      "2020-06-28 09:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1211270> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 哪吒之魔童降世\n",
      " 动画 喜剧 奇幻\n",
      "2019-07-26中国大陆上映\n",
      "2020-06-28 09:04:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1211270>\n",
      "{'film_name': '哪吒之魔童降世',\n",
      " 'film_type': ' 动画 喜剧 奇幻',\n",
      " 'plan_time': '2019-07-26中国大陆上映'}\n",
      "2020-06-28 09:04:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1218029> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 少年的你\n",
      " 爱情 青春 剧情\n",
      "2019-10-25中国大陆上映\n",
      "2020-06-28 09:04:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1218029>\n",
      "{'film_name': '少年的你', 'film_type': ' 爱情 青春 剧情', 'plan_time': '2019-10-25中国大陆上映'}\n",
      "2020-06-28 09:04:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/246061> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 哥斯拉2：怪兽之王\n",
      " 科幻 灾难 动作\n",
      "2019-05-31中国大陆上映\n",
      "2020-06-28 09:04:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/246061>\n",
      "{'film_name': '哥斯拉2：怪兽之王',\n",
      " 'film_type': ' 科幻 灾难 动作',\n",
      " 'plan_time': '2019-05-31中国大陆上映'}\n",
      "2020-06-28 09:04:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1251639> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 毒液2\n",
      " 动作 科幻 惊悚 恐怖\n",
      "2020-06-25美国上映\n",
      "2020-06-28 09:04:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1251639>\n",
      "{'film_name': '毒液2', 'film_type': ' 动作 科幻 惊悚 恐怖', 'plan_time': '2020-06-25美国上映'}\n",
      "2020-06-28 09:04:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/344264> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 战狼2\n",
      " 动作 战争\n",
      "2017-07-27中国大陆上映\n",
      "2020-06-28 09:04:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/344264>\n",
      "{'film_name': '战狼2', 'film_type': ' 动作 战争', 'plan_time': '2017-07-27中国大陆上映'}\n",
      "2020-06-28 09:04:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1227006> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 吹哨人\n",
      " 剧情 犯罪 悬疑\n",
      "2019-12-06中国大陆上映\n",
      "2020-06-28 09:04:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1227006>\n",
      "{'film_name': '吹哨人', 'film_type': ' 剧情 犯罪 悬疑', 'plan_time': '2019-12-06中国大陆上映'}\n",
      "2020-06-28 09:04:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/343355> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 恐怖电影院2\n",
      " 恐怖 惊悚\n",
      "2017-10-20中国大陆上映\n",
      "2020-06-28 09:04:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/343355>\n",
      "{'film_name': '恐怖电影院2', 'film_type': ' 恐怖 惊悚', 'plan_time': '2017-10-20中国大陆上映'}\n",
      "2020-06-28 09:04:18 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2020-06-28 09:04:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 5776,\n",
      " 'downloader/request_count': 12,\n",
      " 'downloader/request_method_count/GET': 12,\n",
      " 'downloader/response_bytes': 425921,\n",
      " 'downloader/response_count': 12,\n",
      " 'downloader/response_status_count/200': 12,\n",
      " 'elapsed_time_seconds': 39.436837,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2020, 6, 28, 1, 4, 18, 449383),\n",
      " 'item_scraped_count': 10,\n",
      " 'log_count/DEBUG': 22,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 51109888,\n",
      " 'memusage/startup': 51105792,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 12,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/200': 1,\n",
      " 'scheduler/dequeued': 11,\n",
      " 'scheduler/dequeued/memory': 11,\n",
      " 'scheduler/enqueued': 11,\n",
      " 'scheduler/enqueued/memory': 11,\n",
      " 'start_time': datetime.datetime(2020, 6, 28, 1, 3, 39, 12546)}\n",
      "2020-06-28 09:04:18 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy crawl maoyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-28 09:02:00 [scrapy.utils.log] INFO: Scrapy 2.1.0 started (bot: assigment_2)\n",
      "2020-06-28 09:02:00 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 13:42:34) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.4.0-x86_64-i386-64bit\n",
      "2020-06-28 09:02:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2020-06-28 09:02:00 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'assigment_2',\n",
      " 'DOWNLOAD_DELAY': 2,\n",
      " 'NEWSPIDER_MODULE': 'assigment_2.spiders',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_MODULES': ['assigment_2.spiders'],\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, '\n",
      "               'like Gecko) Chrome/19.0.1062.0 Safari/536.3'}\n",
      "2020-06-28 09:02:00 [scrapy.extensions.telnet] INFO: Telnet Password: 5ca0310685f29d40\n",
      "2020-06-28 09:02:00 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2020-06-28 09:02:00 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2020-06-28 09:02:00 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2020-06-28 09:02:00 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2020-06-28 09:02:00 [scrapy.core.engine] INFO: Spider opened\n",
      "2020-06-28 09:02:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2020-06-28 09:02:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2020-06-28 09:02:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/robots.txt> (referer: None)\n",
      "2020-06-28 09:02:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://verify.meituan.com/v2/web/general_page?action=spiderindefence&requestCode=e7835dec0a114190a690340238fa11bb&platform=1000&adaptor=auto&succCallbackUrl=https%3A%2F%2Foptimus-mtsi.meituan.com%2Foptimus%2FverifyResult%3ForiginUrl%3Dhttp%253A%252F%252Fmaoyan.com%252Ffilms%253FshowType%253D3> from <GET https://maoyan.com/films?showType=3>\n",
      "2020-06-28 09:02:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://verify.meituan.com/robots.txt> (referer: None)\n",
      "2020-06-28 09:02:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://verify.meituan.com/v2/web/general_page?action=spiderindefence&requestCode=e7835dec0a114190a690340238fa11bb&platform=1000&adaptor=auto&succCallbackUrl=https%3A%2F%2Foptimus-mtsi.meituan.com%2Foptimus%2FverifyResult%3ForiginUrl%3Dhttp%253A%252F%252Fmaoyan.com%252Ffilms%253FshowType%253D3> (referer: None)\n",
      "2020-06-28 09:02:06 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2020-06-28 09:02:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 1535,\n",
      " 'downloader/request_count': 4,\n",
      " 'downloader/request_method_count/GET': 4,\n",
      " 'downloader/response_bytes': 17124,\n",
      " 'downloader/response_count': 4,\n",
      " 'downloader/response_status_count/200': 3,\n",
      " 'downloader/response_status_count/302': 1,\n",
      " 'elapsed_time_seconds': 6.34972,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2020, 6, 28, 1, 2, 6, 995813),\n",
      " 'log_count/DEBUG': 4,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 51195904,\n",
      " 'memusage/startup': 51191808,\n",
      " 'response_received_count': 3,\n",
      " 'robotstxt/request_count': 2,\n",
      " 'robotstxt/response_count': 2,\n",
      " 'robotstxt/response_status_count/200': 2,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2020, 6, 28, 1, 2, 0, 646093)}\n",
      "2020-06-28 09:02:06 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy view \"https://maoyan.com/films?showType=3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from assigment_2.items import Assigment2Item\n",
    "from scrapy.selector import Selector\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Selector in module scrapy.selector.unified:\n",
      "\n",
      "class Selector(parsel.selector.Selector, scrapy.utils.trackref.object_ref)\n",
      " |  Selector(*args, **kwargs)\n",
      " |  \n",
      " |  An instance of :class:`Selector` is a wrapper over response to select\n",
      " |  certain parts of its content.\n",
      " |  \n",
      " |  ``response`` is an :class:`~scrapy.http.HtmlResponse` or an\n",
      " |  :class:`~scrapy.http.XmlResponse` object that will be used for selecting\n",
      " |  and extracting data.\n",
      " |  \n",
      " |  ``text`` is a unicode string or utf-8 encoded text for cases when a\n",
      " |  ``response`` isn't available. Using ``text`` and ``response`` together is\n",
      " |  undefined behavior.\n",
      " |  \n",
      " |  ``type`` defines the selector type, it can be ``\"html\"``, ``\"xml\"``\n",
      " |  or ``None`` (default).\n",
      " |  \n",
      " |  If ``type`` is ``None``, the selector automatically chooses the best type\n",
      " |  based on ``response`` type (see below), or defaults to ``\"html\"`` in case it\n",
      " |  is used together with ``text``.\n",
      " |  \n",
      " |  If ``type`` is ``None`` and a ``response`` is passed, the selector type is\n",
      " |  inferred from the response type as follows:\n",
      " |  \n",
      " |  * ``\"html\"`` for :class:`~scrapy.http.HtmlResponse` type\n",
      " |  * ``\"xml\"`` for :class:`~scrapy.http.XmlResponse` type\n",
      " |  * ``\"html\"`` for anything else\n",
      " |  \n",
      " |  Otherwise, if ``type`` is set, the selector type will be forced and no\n",
      " |  detection will occur.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Selector\n",
      " |      parsel.selector.Selector\n",
      " |      scrapy.utils.trackref.object_ref\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, response=None, text=None, type=None, root=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  response\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  selectorlist_cls = <class 'scrapy.selector.unified.SelectorList'>\n",
      " |      The :class:`SelectorList` class is a subclass of the builtin ``list``\n",
      " |      class, which provides a few additional methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from parsel.selector.Selector:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |      Return ``True`` if there is any real content selected or ``False``\n",
      " |      otherwise.  In other words, the boolean value of a :class:`Selector` is\n",
      " |      given by the contents it selects.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  __repr__ = __str__(self)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  css(self, query)\n",
      " |      Apply the given CSS selector and return a :class:`SelectorList` instance.\n",
      " |      \n",
      " |      ``query`` is a string containing the CSS selector to apply.\n",
      " |      \n",
      " |      In the background, CSS queries are translated into XPath queries using\n",
      " |      `cssselect`_ library and run ``.xpath()`` method.\n",
      " |      \n",
      " |      .. _cssselect: https://pypi.python.org/pypi/cssselect/\n",
      " |  \n",
      " |  extract = get(self)\n",
      " |  \n",
      " |  get(self)\n",
      " |      Serialize and return the matched nodes in a single unicode string.\n",
      " |      Percent encoded content is unquoted.\n",
      " |  \n",
      " |  getall(self)\n",
      " |      Serialize and return the matched node in a 1-element list of unicode strings.\n",
      " |  \n",
      " |  re(self, regex, replace_entities=True)\n",
      " |      Apply the given regex and return a list of unicode strings with the\n",
      " |      matches.\n",
      " |      \n",
      " |      ``regex`` can be either a compiled regular expression or a string which\n",
      " |      will be compiled to a regular expression using ``re.compile(regex)``.\n",
      " |      \n",
      " |      By default, character entity references are replaced by their\n",
      " |      corresponding character (except for ``&amp;`` and ``&lt;``).\n",
      " |      Passing ``replace_entities`` as ``False`` switches off these\n",
      " |      replacements.\n",
      " |  \n",
      " |  re_first(self, regex, default=None, replace_entities=True)\n",
      " |      Apply the given regex and return the first unicode string which\n",
      " |      matches. If there is no match, return the default value (``None`` if\n",
      " |      the argument is not provided).\n",
      " |      \n",
      " |      By default, character entity references are replaced by their\n",
      " |      corresponding character (except for ``&amp;`` and ``&lt;``).\n",
      " |      Passing ``replace_entities`` as ``False`` switches off these\n",
      " |      replacements.\n",
      " |  \n",
      " |  register_namespace(self, prefix, uri)\n",
      " |      Register the given namespace to be used in this :class:`Selector`.\n",
      " |      Without registering namespaces you can't select or extract data from\n",
      " |      non-standard namespaces. See :ref:`selector-examples-xml`.\n",
      " |  \n",
      " |  remove(self)\n",
      " |      Remove matched nodes from the parent element.\n",
      " |  \n",
      " |  remove_namespaces(self)\n",
      " |      Remove all namespaces, allowing to traverse the document using\n",
      " |      namespace-less xpaths. See :ref:`removing-namespaces`.\n",
      " |  \n",
      " |  xpath(self, query, namespaces=None, **kwargs)\n",
      " |      Find nodes matching the xpath ``query`` and return the result as a\n",
      " |      :class:`SelectorList` instance with all elements flattened. List\n",
      " |      elements implement :class:`Selector` interface too.\n",
      " |      \n",
      " |      ``query`` is a string containing the XPATH query to apply.\n",
      " |      \n",
      " |      ``namespaces`` is an optional ``prefix: namespace-uri`` mapping (dict)\n",
      " |      for additional prefixes to those registered with ``register_namespace(prefix, uri)``.\n",
      " |      Contrary to ``register_namespace()``, these prefixes are not\n",
      " |      saved for future calls.\n",
      " |      \n",
      " |      Any additional named arguments can be used to pass values for XPath\n",
      " |      variables in the XPath expression, e.g.::\n",
      " |      \n",
      " |          selector.xpath('//a[href=$url]', url=\"http://www.example.com\")\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from parsel.selector.Selector:\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  attrib\n",
      " |      Return the attributes dictionary for underlying element.\n",
      " |  \n",
      " |  namespaces\n",
      " |  \n",
      " |  root\n",
      " |  \n",
      " |  text\n",
      " |  \n",
      " |  type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from scrapy.utils.trackref.object_ref:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-50e98c51f3ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_requests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'start_requests' is not defined"
     ]
    }
   ],
   "source": [
    "help(start_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-28 09:29:16 [scrapy.utils.log] INFO: Scrapy 2.1.0 started (bot: assigment_2)\n",
      "2020-06-28 09:29:16 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (default, Jan  8 2020, 13:42:34) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.4.0-x86_64-i386-64bit\n",
      "2020-06-28 09:29:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2020-06-28 09:29:16 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'assigment_2',\n",
      " 'DOWNLOAD_DELAY': 2,\n",
      " 'NEWSPIDER_MODULE': 'assigment_2.spiders',\n",
      " 'ROBOTSTXT_OBEY': True,\n",
      " 'SPIDER_MODULES': ['assigment_2.spiders'],\n",
      " 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, '\n",
      "               'like Gecko) Chrome/19.0.1055.1 Safari/535.24'}\n",
      "2020-06-28 09:29:16 [scrapy.extensions.telnet] INFO: Telnet Password: a9ef395e43e680d4\n",
      "2020-06-28 09:29:16 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2020-06-28 09:29:17 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2020-06-28 09:29:17 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2020-06-28 09:29:17 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "['assigment_2.pipelines.Assigment2Pipeline']\n",
      "2020-06-28 09:29:17 [scrapy.core.engine] INFO: Spider opened\n",
      "2020-06-28 09:29:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2020-06-28 09:29:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2020-06-28 09:29:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/robots.txt> (referer: None)\n",
      "2020-06-28 09:29:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films?showType=3> (referer: None)\n",
      "https://maoyan.com/films/1250952\n",
      "https://maoyan.com/films/1218273\n",
      "https://maoyan.com/films/344990\n",
      "https://maoyan.com/films/1211270\n",
      "2020-06-28 09:29:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1250952> (referer: https://maoyan.com/films?showType=3)\n",
      "https://maoyan.com/films/1218029\n",
      "https://maoyan.com/films/246061\n",
      "2020-06-28 09:29:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1218273> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 天气之子\n",
      " 爱情 动画 奇幻\n",
      "2019-11-01中国大陆上映\n",
      "2020-06-28 09:29:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1250952>\n",
      "{'film_name': '天气之子', 'film_type': ' 爱情 动画 奇幻', 'plan_time': '2019-11-01中国大陆上映'}\n",
      "https://maoyan.com/films/1251639\n",
      "https://maoyan.com/films/344264\n",
      "测试 误杀\n",
      " 剧情 犯罪\n",
      "2019-12-13中国大陆上映\n",
      "2020-06-28 09:29:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1218273>\n",
      "{'film_name': '误杀', 'film_type': ' 剧情 犯罪', 'plan_time': '2019-12-13中国大陆上映'}\n",
      "https://maoyan.com/films/1227006\n",
      "2020-06-28 09:29:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/344990> (referer: https://maoyan.com/films?showType=3)\n",
      "https://maoyan.com/films/343355\n",
      "测试 唐人街探案2\n",
      " 喜剧 动作 悬疑\n",
      "2018-02-16中国大陆上映\n",
      "2020-06-28 09:29:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/344990>\n",
      "{'film_name': '唐人街探案2',\n",
      " 'film_type': ' 喜剧 动作 悬疑',\n",
      " 'plan_time': '2018-02-16中国大陆上映'}\n",
      "2020-06-28 09:29:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1211270> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 哪吒之魔童降世\n",
      " 动画 喜剧 奇幻\n",
      "2019-07-26中国大陆上映\n",
      "2020-06-28 09:29:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1211270>\n",
      "{'film_name': '哪吒之魔童降世',\n",
      " 'film_type': ' 动画 喜剧 奇幻',\n",
      " 'plan_time': '2019-07-26中国大陆上映'}\n",
      "2020-06-28 09:29:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/246061> (referer: https://maoyan.com/films?showType=3)\n",
      "2020-06-28 09:29:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1218029> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 哥斯拉2：怪兽之王\n",
      " 科幻 灾难 动作\n",
      "2019-05-31中国大陆上映\n",
      "2020-06-28 09:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/246061>\n",
      "{'film_name': '哥斯拉2：怪兽之王',\n",
      " 'film_type': ' 科幻 灾难 动作',\n",
      " 'plan_time': '2019-05-31中国大陆上映'}\n",
      "测试 少年的你\n",
      " 爱情 青春 剧情\n",
      "2019-10-25中国大陆上映\n",
      "2020-06-28 09:29:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1218029>\n",
      "{'film_name': '少年的你', 'film_type': ' 爱情 青春 剧情', 'plan_time': '2019-10-25中国大陆上映'}\n",
      "2020-06-28 09:29:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1251639> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 毒液2\n",
      " 动作 科幻 惊悚 恐怖\n",
      "2020-06-25美国上映\n",
      "2020-06-28 09:29:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1251639>\n",
      "{'film_name': '毒液2', 'film_type': ' 动作 科幻 惊悚 恐怖', 'plan_time': '2020-06-25美国上映'}\n",
      "2020-06-28 09:29:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/344264> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 战狼2\n",
      " 动作 战争\n",
      "2017-07-27中国大陆上映\n",
      "2020-06-28 09:29:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/344264>\n",
      "{'film_name': '战狼2', 'film_type': ' 动作 战争', 'plan_time': '2017-07-27中国大陆上映'}\n",
      "2020-06-28 09:29:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/1227006> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 吹哨人\n",
      " 剧情 犯罪 悬疑\n",
      "2019-12-06中国大陆上映\n",
      "2020-06-28 09:29:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/1227006>\n",
      "{'film_name': '吹哨人', 'film_type': ' 剧情 犯罪 悬疑', 'plan_time': '2019-12-06中国大陆上映'}\n",
      "2020-06-28 09:29:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://maoyan.com/films/343355> (referer: https://maoyan.com/films?showType=3)\n",
      "测试 恐怖电影院2\n",
      " 恐怖 惊悚\n",
      "2017-10-20中国大陆上映\n",
      "2020-06-28 09:29:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://maoyan.com/films/343355>\n",
      "{'film_name': '恐怖电影院2', 'film_type': ' 恐怖 惊悚', 'plan_time': '2017-10-20中国大陆上映'}\n",
      "2020-06-28 09:29:56 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2020-06-28 09:29:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 5692,\n",
      " 'downloader/request_count': 12,\n",
      " 'downloader/request_method_count/GET': 12,\n",
      " 'downloader/response_bytes': 425931,\n",
      " 'downloader/response_count': 12,\n",
      " 'downloader/response_status_count/200': 12,\n",
      " 'elapsed_time_seconds': 38.956055,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2020, 6, 28, 1, 29, 56, 26663),\n",
      " 'item_scraped_count': 10,\n",
      " 'log_count/DEBUG': 22,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 51089408,\n",
      " 'memusage/startup': 51089408,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 12,\n",
      " 'robotstxt/request_count': 1,\n",
      " 'robotstxt/response_count': 1,\n",
      " 'robotstxt/response_status_count/200': 1,\n",
      " 'scheduler/dequeued': 11,\n",
      " 'scheduler/dequeued/memory': 11,\n",
      " 'scheduler/enqueued': 11,\n",
      " 'scheduler/enqueued/memory': 11,\n",
      " 'start_time': datetime.datetime(2020, 6, 28, 1, 29, 17, 70608)}\n",
      "2020-06-28 09:29:56 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy crawl maoyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
