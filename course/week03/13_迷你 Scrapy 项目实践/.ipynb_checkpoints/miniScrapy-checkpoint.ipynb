{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import threading\n",
    "from lxml import etree\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrawlThread(threading.Thread):\n",
    "    '''\n",
    "    爬虫线程类\n",
    "    '''\n",
    "    def __init__(self, thread_id, page_queue):\n",
    "        super().__init__()\n",
    "        self.thread_id = thread_id\n",
    "        self.page_queue = page_queue\n",
    "    \n",
    "    def run(self):\n",
    "        '''\n",
    "        重写run()\n",
    "        '''\n",
    "        print(f'启动线程： {self.thread_id}')\n",
    "        self.scheduler()\n",
    "        print(f'结束线程： {self.thread_id}')\n",
    "    \n",
    "    #任务调度：\n",
    "    def scheduler(self):\n",
    "        while True:\n",
    "            #队列为空不处理\n",
    "            if self.page_queue.empty():\n",
    "                break\n",
    "            else:\n",
    "                page = self.page_queue.get()\n",
    "                print(f'下载线程{self.thread_id}, 下载页码{page}')\n",
    "                url = f'https://book.douban.com/top250?start={page*25}'\n",
    "                headers = {\n",
    "                    'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36'\n",
    "                }\n",
    "                try:\n",
    "                    # downloader 下载器\n",
    "                    response = requests.get(url, headers=headers)\n",
    "                    dataQueue.put(response.text)\n",
    "                except Exception as e:\n",
    "                    print('出现异常：', e)\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParserThread(threading.Thread):\n",
    "    '''\n",
    "    页面内容分析线程类\n",
    "    '''\n",
    "    def __init__(self, thread_id, data_queue, file):\n",
    "        super().__init__()\n",
    "        self.thread_id = thread_id\n",
    "        self.data_queue = data_queue\n",
    "        self.file = file\n",
    "    \n",
    "    def run(self):\n",
    "        print(f'启动线程{self.thread_id}')\n",
    "        while not flag:\n",
    "            try:\n",
    "                item = self.data_queue.get(False)\n",
    "                if not item:\n",
    "                    pass\n",
    "                self.parse_data(item)\n",
    "                self.data_queue.task_done()  # get之后检测是否会阻塞\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        print(f'结束线程{self.thread_id}')\n",
    "    \n",
    "    #页面内容分析：\n",
    "    def parse_data(self, item):\n",
    "        '''\n",
    "        解析网页内容的函数\n",
    "        :param item:\n",
    "        :return:\n",
    "        '''\n",
    "        try:\n",
    "            html = etree.HTML(item)\n",
    "            books = html.xpath('//div[@class=\"pl2\"]')\n",
    "            try:\n",
    "                for book in books:\n",
    "                    title = book.xpath('./a/text()')\n",
    "                    link = book.xpath('./a/@href')\n",
    "                    response={\n",
    "                        'title': title,\n",
    "                        'link': link\n",
    "                    }\n",
    "                    #解析方法和scrapy相同，再构造一个json\n",
    "                    json.dump(response, fp=self.file, ensure_ascii=False)\n",
    "            except Exception as e:\n",
    "                print('Book Error.', e)\n",
    "        except Exception as e:\n",
    "            print('Page Error.', e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存放解析数据的queue\n",
    "dataQueue = Queue()\n",
    "#控制ParserThread标签：\n",
    "flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "启动线程： crawl_1\n",
      "下载线程crawl_1, 下载页码0\n",
      "启动线程： crawl_2\n",
      "下载线程crawl_2, 下载页码1\n",
      "启动线程： crawl_3\n",
      "下载线程crawl_3, 下载页码2\n",
      "启动线程parse_1\n",
      "启动线程parse_2\n",
      "启动线程parse_3\n",
      "下载线程crawl_1, 下载页码3\n",
      "下载线程crawl_3, 下载页码4\n",
      "下载线程crawl_2, 下载页码5\n",
      "下载线程crawl_1, 下载页码6\n",
      "下载线程crawl_3, 下载页码7\n",
      "下载线程crawl_2, 下载页码8\n",
      "下载线程crawl_3, 下载页码9\n",
      "下载线程crawl_1, 下载页码10结束线程： crawl_2\n",
      "\n",
      "结束线程： crawl_1\n",
      "结束线程： crawl_3\n",
      "结束线程parse_1结束线程parse_2\n",
      "\n",
      "结束线程parse_3\n",
      "退出主线程。\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 将结果保存到一个json文件中\n",
    "    output = open('books.json', 'a', encoding='utf-8')\n",
    "    \n",
    "    # 任务队列，存放网页的队列\n",
    "    page_queue = Queue(20)\n",
    "    for i in range(11):\n",
    "        page_queue.put(i)\n",
    "    \n",
    "    # 爬虫线程\n",
    "    crawl_threads = []\n",
    "    crawl_name_list = ['crawl_1', 'crawl_2', 'crawl_3']\n",
    "    for thread_id in crawl_name_list:\n",
    "        thread = CrawlThread(thread_id, page_queue)\n",
    "        thread.start()\n",
    "        crawl_threads.append(thread)\n",
    "    \n",
    "    # 解析线程\n",
    "    parse_threads = []\n",
    "    parse_name_list = ['parse_1', 'parse_2', 'parse_3']\n",
    "    for thread_id in parse_name_list:\n",
    "        thread = ParserThread(thread_id, dataQueue, output)\n",
    "        thread.start()\n",
    "        parse_threads.append(thread)\n",
    "        \n",
    "    # 结束crawl线程\n",
    "    for thread in crawl_threads:\n",
    "        thread.join()\n",
    "        \n",
    "    # 结束parse线程\n",
    "    flag = True\n",
    "    for thread in parse_threads:\n",
    "        thread.join()\n",
    "        \n",
    "    output.close()\n",
    "    print('退出主线程。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
